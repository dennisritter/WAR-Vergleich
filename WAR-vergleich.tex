\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

% Template packages
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

% Custom Packages
\usepackage[utf8]{inputenc}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Hörsaalspiele als Unterrichtselement - Ein Vergleich zwischen zwei Umsetzungen}

\author{\IEEEauthorblockN{1\textsuperscript{st} xxxxxxxxxxxx}
\IEEEauthorblockA{\textit{Medieninformatik Master} \\
\textit{Beuth Hochschule für Technik Berlin}\\
Berlin, Germany \\
xyz@abc.com}
}

\maketitle

\begin{abstract}
Hörsaalspiele und Gamification Elemente können eine sinnvolle Ergänzung zu weiteren Inhalten innerhalb von Lehrveranstaltungen darstellen. Es existieren bereits mehrere und unterschiedliche Konzepte und Umsetzungen solcher Hörsaalspiele. Um verschiedene Konzepte mit Bezug zueinander genauer zu untersuchen, werden deshalb zwei Hörsaalspiele exemplarisch ausgewählt und anhand ausgewählter Kriterien miteinander verglichen. Im Anschluss an eine Kriterienorientierte Analyse und Bewertung, werden außerdem Einsatz- und Weiterentwicklungsempfehlungen auf Basis der gewonnenen Erkenntnisse dargelegt.
\end{abstract}

%\begin{IEEEkeywords}
%component, formatting, style, styling, insert
%\end{IEEEkeywords}

\section{Einleitung}
Hörsaalspiele können in Unterrichtsveranstaltungen eingesetzt werden, um das Lernklima zu verbessern. Sie fördern die aktive Einbeziehung Lernender und ermöglichen es der Lehrkraft direktes Feedback von diesen zu erhalten. Sie unterstützen sowohl die Interaktion Lernender untereinander als auch zwischen Lernenden und Lehrendem. Dies kann unter anderem den Lernerfolg, soziale Kompetenzen und Motivation positiv beeinflussen. \cite[S. 368]{Lehmann2014} Eine Methode Hörsaalspiele in einzusetzen sind Audience Response Systeme (ARS). 
% Grundsätzlich läuft der Einsatz eines ARS so ab, dass die Lehrkraft Fragen präsentiert und allen Lernenden ermöglicht wird diese zu beantworten. Durch die im Anschluss präsentierte Antwort folgt ein direktes Feedback.

Ziel dieser Arbeit ist es, zwei Lösungskonzepte für ARS anhand ausgewählter Kriterien zu untersuchen und anschließend auf dieser Basis miteinander zu vergleichen. Dafür wird zunächst der aktuelle Forschungs- und Entwicklungsstand zu Hörsaalspielen und ARS untersucht, sowie zwei ARS Lösungskonzepte ausgewählt. Im Anschluss werden die zwei ausgewählten Systeme vorgestellt und die Vergleichskriterien ermittelt, um die vorgestellten Systeme anhand dieser Kriterien zu analysieren. 
Auf Basis der Analyse wird Ferner eine Bewertung stattfinden und gegebenenfalls ein geeigneter Anwendungskontext vorgeschlagen, in dem der Einsatz der beiden ARS sinnvoll sein könnte.

\section{Aktueller Stand}
% Quelle?
\subsection{Audience Response Systeme}
Audience Response Systeme, auch Classroom Response Systeme (CRS) genannt, erlauben es einer gesamten Zuhörerschaft Fragen des Vortragenden zu beantworten. Die Antworten können im Anschluss direkt von der Software verarbeitet werden, was ein unmittelbares Feedback ermöglicht. Die erhaltenen Daten können beispielsweise anschaulich dargestellt oder in einen Wettkampfkontext in Form eines Einzel- oder teambasierten Ratespiels eingebunden werden. Welche und wieviele Funktionen ein ARS genau unterstützt hängt von der jeweiligen Umsetzung ab. Beispiele für Individualisierungen könnten dabei die Anzahl und Art unterstützter Fragen- und Aufgabentypen, Form und Umfang des anschließenden Feedbacks, das Design der Anwendung oder die Vorgehensweise konkrete Fragen in die Appplikation zu integrieren sein. 

Es kann bei ARS zwischen zwei Typen unterschieden werden. Zum einen hardwarebasierte und zum anderen Softwarebasierte. Bei hardwarebasierten Systemen erhalten die Zuhörer zunächst ein Steuergerät, mit dessen Hilfe präsentierte Fragen beantwortet werden können. Dafür wird z.B. eine Funkverbindung mit dem Gerät auf dem die ARS Software ausgeführt wird hergestellt. 
Softwarebasierte Systeme dagegen sind oftmals webbasierte Anwednungen. Die Interaktion findet hier mit Hilfe einer Software, wie zum Beispiel einer Web-Applikation oder Smartphone App statt. Das Steuergerät stellt hier der eigene Laptop oder das Smartphone dar.
Im Folgenden werden hardwarebasierte ARS vernachlässigt, da der Einsatz softwarebasierter ARS unter Verwendung von Smartphones, Tablets und Laptops flexibler ist. \cite[S. 340]{Hobert2017} Es entstehen außerdem keine zusätzlichen Kosten für bereitzustellende Geräte, sofern die Teilnehmer eigene Hardware zur Ausführung der Software besitzen.

%footnotes --> cites
Die Verbreitung mobiler internetfähiger Endgeräte begünstigt die Entwicklung verschiedener softwarebasierter ARS, wie zum Beispiel die frei verfügbare Software ARSnova \cite{Quibeldey-Cirkel2013} oder PINGO, ein ARS welches speziell für sehr große Gruppen ab 100 Personen entwickelt wurde \cite{Reinhardt2012}. Des weiteren existieren Kommerzielle Umsetzungen, wie Feedbackr\footnote[3]{Feedbackr Website - https://www.feedbackr.io/} oder Conferences i/o\footnote[4]{Conferences i/o Website - https://www.conferences.io/}, die kostenpflichtige Lizenzen anbieten, um das Produkt zu nutzen.

\subsection{Quiz Authoring Tools}
Quiz Authoring Tools (QAT) sind Anwendungen, die es Autoren ermöglichen Fragen und gegebenenfalls auch weitere damit zusammenhängende Inhalte zu erstellen. Gründe für die Verwendung von QAT sind unter anderem Zeit- und damit einhergehend Geldersparniss sowie eine Vereinfachung bei der Erstellung qualitativ hochwertiger Inhalte. Des weiteren erlauben es QAT wie \emph{Quiz Engine Developer} (QED) Fragen anschließend in standardisierten Formaten zu exportieren, was die Wiederverwendbarkeit der erstellten Inhalte erhöht. Zum Teil treten QAT auch innerhalb von Learning Management Systemen (LMS) wie Moodle oder Blackboard auf, so dass die Erstellung und Darstellung der Inhalte über die selbe Plattform erfolgt. \cite[S. 2]{Gordillo2015} 

\subsection{Vergleichsgegenstand}
Vergleichsgegenstand dieser Arbeit werden zum einen die von Hobert et. al konzipierte und entwickelte Applikation \emph{StudiDuell}\cite{Hobert2017} zum anderen das von Gordillo et. al entwickelte Lösungskonzept zum Verbessern von web-basiertem Lernen (LVWBL) \cite{Gordillo2015} sein. Die genannten Umsetzungen wurden ausgewählt, weil es sich in beiden Fällen um webbasierte Systeme handelt, die sowohl Erstellung als auch Präsentation von Fragen unterstützen. Zudem wurde jeweils eine Evaluation durchgeführt, um ein Feedback für die Prototypen nach dem Einsatz in Lehrveranstaltungen zu erhalten.
\cite{Hobert2017} \cite{Gordillo2015}

Aufgrund der dargelegten Zusammenhänge kann angenommen werden, dass die Arbeiten sich gut eignen einen gemeinsamen Bezug herzustellen und diese anhand von vorher festgelegten Kriterien miteinander zu vergleichen.

\section{Analyse}

\subsection{Vergleichskriterien}
Im folgenden Kapitel werden drei Kriterien festgelegt, damit die zu vergleichenden ARS auf diese Kriterien hin analysiert und folgend miteinander verglichen werden können.
\\
\subsubsection{Management und Administration} 
Ein Gegenstand der Analyse der zu vergleichenden Systeme wird das inhalts- und durchführungsbezogene Management sowie die Administration des jeweils untersuchten ARS sein.

Im Folgenden wird davon ausgegangen, dass Lehrkräfte Inhalte für das im Unterricht zu verwendende ARS selbst erstellen und einpflegen, um daraus zum Beispiel Unterrichtsformate in Form eines Quiz entwerfen. Unter dieser Annahme kann geschlussfolgert werden, dass Lehrkräfte insgesamt mehr Zeit mit dem ARS verbringen, als die Lernenden. Der Umfang und die Qualität des Managements und der Administration des ARS kann deshalb ein wichtiges Kriterium bei der Auswahl für den Unterricht sein. Wie im Kapitel \emph{Quiz Authoring Tools} bereits erwähnt, ist einer der Hauptgründe für die Verwendung von QAT die Zeit- und Geldersparnis. Daraus abgeleitet, wäre es für das Management des ARS von Vorteil, wenn die Lehrkraft möglichst wenig Zeit dafür aufbringen muss. Nimmt man an, dass ein ARS nicht nur in einer Lehrveranstaltung, sondern beispielsweise in einem Fachbereich oder Hochschule verwendet werden soll gewinnt die Qualität der Managementfunktionen an Relevanz, da aus absoluter Sicht mehr Zeit und Geld eingespart werden kann. 
\\
\subsubsection{Integration in den Unterrichtsablauf}
Ein weiteres Kriterium bei der Analyse wird die Integration in den Unterrichtsablauf darstellen.

Umso einfacher das ARS sich in eine Lehrveranstaltung integrieren lässt, desto weniger wird der Unterrichtsablauf gestört, was wiederum eine Zeitersparnis und einen höheren potentiellen Lernerfolg begünstigt. Deshalb werden die zu vergleichenden Systeme dahingehend untersucht, welche Funktionen und Eigenschaften eine möglichst nahtlose Einbindung in eine Lehrveranstaltung begünstigen, bzw. benachteiligen.
\\
\subsubsection{Vorgehensweise bei der Evaluation}
Es wird untersucht werden wie die vorgehensweise bei den vorgenommenen Evaluationen bezüglich der entwickelten Systeme war, um daraus im Anschluss die Aussagekraft dieser abzuleiten.

Es kann angenommen werden, dass eine repräsentative, kritische Evaluation der eigenen Arbeit die zukünftige Weiterentwicklung und Verbesserung des Produkts begünstigt. Zudem können die gewonnenen Erkenntnisse auch für das E-Learning Forschungsumfeld von Bedeutung sein und das Erlangen neuer, darauf aufbauender Erkenntnisse positiv beeinflussen. Ferner wäre es gegebenenfalls möglich besonders sinnvolle oder ungünstige Einsatzszenarien zu identifizieren. 

\subsection{StudiDuell}
\subsubsection{Management und Administration}
StudiDuell besteht aus zwei unterschiedlichen Komponenten. Eine der Komponenten bildet die StudiDuell-App. Sie stellt eine mobile Anwendung dar, mit dessen Hilfe Studierende Zugriff auf die Quizfragen bekommen sowie ihre Antworten eingeben können. Die andere Komponente dient zur Verwaltung und Steuerung des Hörsaalspiels und erlaubt es das Spiel über einen Beamer zu präsentieren. \cite[S. 341]{Hobert2017}

Mit Hilfe der Management-Komponente bereiten Dozierende ein Spielfeld vor. Das Spielfeld besteht aus verschiedenen Themen, zu denen Felder mit einer Punktzahl zugeordnet werden. Jedes Feld repräsentiert eine Frage bezüglich des entsprechenden Themenfeldes. Die Themen, Punktzahlen und Fragen, werden von der Lehrkraft über die Management-Komponente eingepflegt. Dabei die Art der Fragen, wie zum Beispiel Freitext-Fragen, Single- oder Multiple-Choice, festgelegt werden. Ferner kann die Lehrkraft festlegen, in wie vielen Gruppen die Lernenden eingeteilt werden, wobei mindestens zwei Gruppen für den Start des Spiels erforderlich sind. Darüber hinaus kann festgelegt werden ob die Fragen von allen Mitgliedern einer Gruppe beantwortet werden können und die mehrheitsfähige Antwort gezählt wird oder aber nur ein Sprecher der Gruppe eine Antwort abgeben kann. 
Sind alle Parameter der StudiDuell-Session konfiguriert, wird ein QR-Code speziell für diese Spielerunde generiert und über die Management-Anwendung z.B. am Beamer dargestellt. Lernende können anschließend über die andere Komponente, die Smartphone-App, diesen QR-Code einscannen, um an dem Spiel teilzunehmen. \cite[S. 340f]{Hobert2017}

Die Management-Anwendung stellt eine mit Webtechnologien entwickelte Desktop-Anwendung dar. Sie wurde clientseitig mit der Hyper Text Markup Language Version 5 (HTML5)\footnote{Eine textbasierte Auszeichnungssprache zur Strukturierung digitaler Dokumente. Wird größtenteils zum Strukturieren von Internetseiten verwendet} und dem Bootstrap-Framework\footnote{Eine spezielle Sammlung von Gestaltungselementen und Hilfsmitteln für das Webdesign} entwickelt. Serverseitig wurde die Programmiersprache PHP und das Datenbanksystem MySQL zur Umsetzung verwendet. \cite[S. 342]{Hobert2017}

Es ist nicht bekannt, wie einzelne Prozesse und Funktionen der Management-Applikation im Detail umgesetzt worden sind. Es ist deshalb unter anderem nicht bekannt in welcher Form die Fragen innerhalb der Anwendung vorliegen, ob diese nachhaltig persistiert und katalogisiert werden oder ob die Möglichkeit besteht Fragen oder ein Quiz zu importieren oder exportieren. Aus diesem Grund kann keine Aussage darüber getroffen werden in welchem Maß Zeit bei der Erstellung einer Spielrunde eingespart werden kann, indem z.B. ein zuvor erstelltes Quiz wiederverwendet oder nachträglich bearbeitet werden kann. Ferner kann nicht beurteilt werden ob erstellte Fragen über zusätzliche Metadaten verfügen oder sich die Erstellung von Inhalten von der Management-Anwendung durch eine Import Funktion entkoppelt wurde. 
\\
\subsubsection{Integration in den Unterrichtsablauf}
Zum starten des Hörsaalspiels muss zunächst die Management-Desktop-Anwendung von der Lehrkraft gestartet und ein QR-Code für die Spielrunde erstellt werden. Der erstellte QR-Code wird anschließend über den Beamer angezeigt. Lernende benötigen ein mobiles, internetfähiges Endgerät, auf dem die StudiDuell-App installiert ist. Mit Hilfe der App ist es dann möglich, den angezeigten QR-Code zu scannen und so an der Spielrunde teilzunehmen. Folgend wird das Spiel durch die Lehrkraft gestartet indem sie von einer Gruppe eine Frage auswählen lässt. Das korrekte Beantworten einer Frage wird mit dem vordefninierten Punktewert für die jeweilige Gruppe belohnt. Dieser Prozess wiederholt sich bis das Quiz beendet ist. Das Team mit den meisten gesammelten Punkten gewinnt. \cite[S. 340f]{Hobert2017}
\\
\subsubsection{Vorgehensweise bei der Evaluation}
Gegenstand der Evaluation war die mobile Applikation mit der Lernende am Quiz teilnehmen. Die Management-Anwendung wurde abgesehen von nach außen hin sichtbaren gestalterischen Aspekten nicht evaluiert. Die Evaluation der mobilen App wurde im Rahmen einer Lehrveranstaltung mit 30 Wirtschaftsinformatik Studenten im Alter von 21 bis 24 Jahren an der Universität Göttingen durchgeführt. Dazu wurde ein quantitativer Fragebogen auf Basis des Technology Acceptance Models (TAM) \cite[S. 985]{Davis1989} entworfen mit dem die wahrgenommene Nützlichkeit und Einfachheit der Anwendung ermittelt worden ist. Die Beantwortung des Fragebogens erfolgte über eine fünfstellige Likert-Skala (-2 trifft nicht zu; +2 trifft zu)zu jeder formulierten Aussage.\cite[S. 342]{Hobert2017}

\subsection{LVWBL}
\subsubsection{Management und Administration}
Das namenlose \emph{Lösungskonzept zum Verbessern von web-basiertem Lernen} von Gordillo et. al basiert auf einem Authoring Tool das im Rahmen des Visual Science Hub Projekts (ViSH) \cite{Barra2014} entwickelt wurde. Mit Hilfe dieses frei verfügbaren Authoring Tools, dem ViSH Editor, können sogenannte Learning Objects (LO) erstellt werden. Diese LOs können dann mit dem ViSH Viewer, der zweiten Hauptkomponente neben dem Authoring Tool, in Form einer Präsentation dargestellt und zu Unterrichtszwecken verwendet werden. Beide Komponenten stellen auf HTML5 basierende Web-Anwendungen dar. Der ViSH Editor funktioniert nach dem \emph{What you see is what you get} (WYSIWYG) Prinzip und ist in verschiedenen Sprachen, wie u.a. Englisch, Deutsch, Französisch und Spanisch verfügbar. Zum Erstellen der LOs können Autoren verschiedene Ressourcen einbinden. Dies beinhaltet z.B. Bilder, Videos, Dokumente und Internetseiten. Zusätzlich ist es möglich eigenen Text einzubinden oder verschiedene Arten von Quizzes zu erstellen und mit einzubinden. Eine Beliebige Kombination von einzelnen Ressource können dann zu einem Slide zusammengefasst werden. Mehrere Slides können wiederum in einem Slideset kombiniert werden. Es entsteht eine interaktive Präsentation bestehend aus einem oder mehreren Slidesets. Erstellte LOs liegen innerhalb der Anwendung im JavaScript Object Notation (JSON)\footnote{Die JavaScript Object Notation ist ein verbreitetes digitales Datenaustauschformat} Datenformat vor. Die LOs können zudem mit Metadaten gemäß des IEEE LOM Standard angereichert werden und als \emph{Sharable Content Object Reference Model} (SCORM) Objekte exportiert werden, um diese innerhalb von Lern-Management Applikationen wie Moodle zu verwenden. \cite[S. 3]{Gordillo2015}

Benutzern des ViSH Editors ist es möglich zwischen fünf verschiedenen Arten von Fragen zu wählen. Die verfügbaren Optionen sind Kurzantwort, Multiple Choice, Mehrfachantwort, Wahr-Falsch und Sortieren. Autoren steht bei der Erstellung von Quizzes, bzw. ganzen Präsentationen, jederzeit eine Vorschau aus sicht der Lernenden zur Verfügung. Darüber hinaus können weitere Einstellungen, wie eine maximale Versuchsanzahl oder das Mischen von Antwortmöglichkeiten vorgenommen werden. Das Importieren von Quizzes aus anderen LOs gehört ebenfalls zu den unterstützten Funktionen. Des weiteren können Ressourcen wie Videos und Sound-Dateien mit anderen Ressourcen wie Fragen verknüpft werden, so dass nach einer bestimmten Abspielzeit z.B. eine Frage bezüglich dessen erscheint. \cite[S. 3f]{Gordillo2015}
\\
\subsubsection{Integration in den Unterrichtsablauf}
Ein mit dem ViSH Editor erstelltes Quiz ist ein Teil einer Gesamtpräsentation die mit dem ViSH Viewer gestartet werden kann. Sofern Lehrkräfte ihre Präsentationen ohnehin mit Hilfe des ViSH Viewers darstellen, muss zum Start eines Quizzes keine zusätzliche Anwendung ausgeführt werden. Wurde ein Quiz in die Präsentation eingebunden, kann es über einen Start-Button von der Lehrkraft gestartet werden. Das ViSH Viewer Tool kommuniziert darauf mit der ARS Schnittstelle (API) der ViSH Plattform und erstellt eine neue Quiz-Session. Eine Quiz-Session identifiziert sich durch eine Quiz-ID (qid) und eine Quiz-URL (qurl), die als Antwort auf die Start-Anfrage an den ViSH Viewer gesendet werden. Sobald der ViSH Viewer die Antwort erhalten hat, erscheint ein Fenster auf dem die qurl und ein QR-Code, der ebenfalls die qurl beinhaltet, abgebildet wird. Es werden zudem weitere Buttons angezeigt, die es ermöglichen das Quiz in social media Kanälen wie \emph{Twitter}, \emph{Facebook} oder \emph{Google Plus} zu teilen. Lernende müssen die qurl über den QR-Code oder manuell innerhalb eines Web-Browsers aufrufen, um zum jeweiligen Quiz zu gelangen und die dazugehörigen Fragen mit Hilfe des ARS beantworten zu können. Für die Beantwortung der Fragen mit Hilfe des ARS wird ein Internetfähiges Gerät, wie ein Smartphone, Tablet oder Laptop benötigt auf dem ein Web-Browser der HTML5 unterstützt installiert ist. Lehrende haben jederzeit die Möglichkeit die bisher abgegebenen Antworten in Echtzeit einzusehen. Die gesammelten Antworten werden dabei abhängig von der Art der Frage in Form von unterschiedlichen Graphen zusammengefasst dargestellt. Es ist der Lehrkraft außerdem möglich die Quiz-Session jederzeit zu beenden. Die gesammelten Daten können darauf in der ViSH Plattform mit einem Namen versehen und gespeichert werden. \cite[S. 6f]{Gordillo2015}
\\
\subsubsection{Vorgehensweise bei der Evaluation}
Für das LVWBL wurden von Gordillo et al. drei unabhängige Evaluationen durchgeführt. Es wurde das ARS aus Sicht der Lehrenden und Lernenden sowie der ViSH Editor mit der Quiz-Funktion evaluiert. Zusätzlich wurden erstellte LOs auf ihre qualitative Verbesserung durch vorhandene Quizzes überprüft. \cite[S. 5ff]{Gordillo2015}

Für die Evaluation des ARS wurden zwei Fragebögen entworfen. Jeweils einer für Lehrkräfte und einer für Lernende. Vor dem Ausfüllen der Fragebögen wurde das ARS in zwei unterschiedlichen Lehrveranstaltungen von Lehrkräften mit ViSH Editor Erfahrung getestet. Als Einstiegshilfe wurde beiden Lehrkräften ein kurzes Tutorial Video, dass die ARS Funktionsweise erklärt, zugeschickt. Darauf wurden von beiden LOs erstellt in denen mindestens ein Quiz vorkommt und in jeweils einer ihrer Lehrveranstaltungen eingesetzt. Nach der jeweiligen Lehrveranstaltung wurden von allen teilnehmern Fragebögen ausgefüllt. Insgesamt wurden so zwei Fragebögen von Lehrkräften und 21 Fragebögen von Lernenden ausgefüllt. Der Studenten-Fragebogen bestand dabei aus drei Fragen. Der Fragebogen für Autoren bestand aus fünf fragen. Die Fragen zielten auf die Nützlichkeit und Einfachheit des ARS ab und spalteten sich in insgesamt drei ja-nein-Fragen und drei Fragen in denen ein bis fünf Punkte vergeben konnten auf. \cite[S. 7]{Gordillo2015}

Für die Evaluation des Authoring Tools wurde ein Fragebogen mit 13 Fragen für ViSH Editor Autoren entworfen. Ziel war es so die Benutzbarkeit und den Gesamteindruck zu überprüfen. Dafür im Dezember 2013 ein Link zum Fragebogen an alle ViSH-Autoren gesendet die innerhalb der letzten drei Monate vor der Evaluation mindestens eine LO auf der ViSH Plattform veröffentlicht haben. Insgesamt wurde der Fragebogen von 67 Autoren ausgefüllt. Diese setzen sich aus Grund- und Oberschullehrern, Dozenten sowie Forschern zusammen, wovon 34 männliche und 33 weibliche Personen im Alter von 19 bis 65 Jahren waren. Alle Fragen sollten mit einer Punktzahl von eins bis fünf beantwortet werden, wobei eine geringere Punktzahl jeweils eine schlechtere Bewertung darstellte als eine hohe. \cite[S. 5]{Gordillo2015}

Um zu überprüfen inwiefern sich die wahrgenommene Qualität von LOs mit vorhandenen Quizzes im Gegensatz zu LOs ohne Quizzes verändert, wurden 209 Präsentationen, die mit dem ViSH Editor erstellt wurden mit Hilfe des \emph{Learning Object Review Instruments} (LORI) Version 1.5\cite{Leacock2007}evaluiert. Dies beinhaltet neun Kriterien zur Bewertung von LOs. Nämlich die Qualität der Inhalte (K1), Ausrichtung an Lernzielen (K2), Feedback und Adaptierung (K3), Motivation (K4), Design der Präsentation (K5), Benutzbarkeit von Interaktionen (K6), Zugänglichkeit (K7), Wiederverwendbarkeit (K8) und Standardkonformität (K9). Die Gruppe der befragten bestand aus 15 Personen und setzte sich aus vier E-Learning Spezialisten, neun Lehrkräften und zwei Designern zusammen. Jede der 209 Präsentation wurde von mindestens drei Personen evaluiert. Insgesamt entstanden so 740 Evaluationen. Zur Beurteilung der Gesamtqualität einer LO wurde ein gewichteter arithmetischer Mittelwert aller LORI Metriken gebildet. Die Gewichtung, welche die relative Relevanz eines Kriteriums abbildet, wurde dafür von den befragten Personen festgelegt. Für LORI Kriterium K1 bis K9 wurde eine Punktzahl von eins bis 5 vergeben. Die jeweilige Punktzahl wurde dann mit der ermittelten Gewichtung multipliziert und mit Konstanten verrechnet, so dass eine Gesamtpunktzahl zwischen Null und Zehn Punkten errechnet wird. Zehn Punkte stellen dabei die höchste Qualität, Null Punkte die
niedrigste Qualität dar. Anschließend wurden die LOs zur Auswertung in zwei Gruppen aufgeteilt, die eine Gruppe bestand aus LOs in denen Quizzes enthalten sind und bestand aus 47 Items. Die andere Gruppe beinhaltete 162 LOs in denen keine Quizzes vorkamen. Um festzustellen wie groß die Unterschiede der Bewertung zwischen den beiden Gruppen sind, wurden exemplarische T-Tests durchgeführt. Außerdem wurde \emph{Cohens d Effektgröße} \cite{CohenJ1992} benutzt, um eine konkrete und messbare Bedeutung unterschiedlicher Bewertungen zu erhalten. Zuletzt wurden unerwartet gute Ergebnisse, wie sie bei K2 vorkamen, kritisch hinterfragt und ergründet, indem ein Qualitätsunterschied nicht nur aufgrund der Präsenz von Quizzes vermutet wurde. Eine Vermutung war, dass Autoren von LOs mit quizzes womöglich erfahrenere und bessere Autoren sein könnten als jene von LOs ohne Quizzes.

\section{Bewertung}
Im folgenden Kapitel werden die in der Analyse gewonnenen Erkenntnisse der zu vergleichenden ARS und Authoring Tools miteinander in Bezug gesetzt, interpretiert und bewertet.

\subsection{Management und Administration}
Im Paper zur LVWBL (A) haben Gordillo et. al wesentlich detaillierter beschrieben wie Inhalte mit Hilfe des Authoring Tools erstellt werden, als es im Paper zum StudiDuell (B) von Hobrecht et. al getan wurde. 

In A der ViSH Editor als Authoring Tool vorgestellt, welcher nicht im Rahmen dieser Arbeit entwickelt, sondern lediglich erweitert wurde, um auch die Erstellung von Quizzes innerhalb von LOs zu ermöglichen. Sofern die Lehrkraft bereits Präsentationen für ihre Lehrveranstaltungen mit Hilfe der ViSH Plattform gestaltet, ist ein solcher Ansatz wünschenswert. Durch die Integration von Quizzes in den ViSH Editor wären Kenntnisse im Umgang mit dem Authoring Tool bereits vorhanden. Es wird zudem kein weiteres Programm benötigt, um Quizzes für eine Lehrveranstaltung anzufertigen oder abzurufen. Für Autoren ohne Erfahrung mit der ViSH Plattform, bzw. ohne Ambitionen ihre Präsentationen mit dem ViSH Editor anzufertigen, könnte dieser Ansatz allerdings hinderlich sein. Denn es müsste zunächst der Umgang mit dem ViSH Editor, der ViSH Plattform, dem ViSH Viewer und dem ARS erlernt werden. Dies stellt einen potentiellen Mehraufwand gegenüber anderen System wie beispielsweise B dar, welche ausschließlich zur Erstellung und Durchführung von Quizzes konzipiert wurden. Auf der anderen Seite wäre es dennoch denkbar, dass das Konzept letztlich trotzdem gut ankommt, weil die Möglichkeit besteht Quizzes mit weiteren Ressourcen anzureichern. So könnte ein Quiz u.a mit Texten, Bildern, Videos verknüpft werden, auch wenn die eigentliche Präsentation der Lehrveranstaltung nicht mit dem ViSH Editor erstellt wurde. Da sich PDF-Dateien mit dem ViSH Editor importieren und in ViSH Präsentationen umwandeln lassen \cite[S. 4]{Gordillo2015}, könnten bei Bedarf sogar Teile der eigentlichen Präsentation mit in das Quiz integriert werden. Der ViSH Editor stellt außerdem weitere nützliche Zusatzfunktionen Bereit, die das Inhalts-Management verbessern. Unter Umständen kann viel Zeit durch die Import- und Export-Funktion von standardisierten SCORM Objekten eingespart werden, wenn zusätzlich mit Lern-Management-Systemen wie Moodle gearbeitet wird. Außerdem wird das Importieren von Quizzes aus anderen LOs ermöglicht, was die Wiederverwendbarkeit erhöht und somit ebenfalls eine potentielle Zeitersparnis darstellt. Des Weiteren begünstigt auch das Learning Object Model (siehe Abb.~\ref{lom}) die Wiederverwendbarkeit von erstellten Ressourcen, weil Slidesets, einzelne Slides und Ressourcen wie Quizzes, Bilder oder Videos voneinander entkoppelt wurden und mehrfach verwendet werden können. Zusätzlich können LOs mit Metadaten angereichert werden, was sich ebenfalls positiv auf die Wiederverwendbarkeit auswirken kann. Der ViSH Editor ist darüber hinaus durch das umgesetzte WYSIWYG Prinzip zum Erstellen von Inhalten einfach zu bedienen und bietet eine Vorschau aus Sicht der Lernenden an, wodurch Fehler vermieden werden können. Um den Editor zu benutzen wird lediglich ein internetfähiges Gerät auf dem ein Webbrowser installiert ist benötigt. Er kann deshalb mit verschiedenen Geräten und von verschiedenen Orten aus mit dem Programm gearbeitet werden ohne das eine Installation nötig ist.

Auch das Management Tool für B stellt eine reine Web-Anwendung dar und lässt sich wie A mit jedem Gerät auf dem ein Webbrowser vorhanden ist verwenden. Mit der Anwendung können Fragen, bzw. ganze Quizzes vom Autor erstellt werden. Die Anzahl der Fragen entscheidet dabei indirekt auch über die Länge des Quizzes. Außerdem können Lehrende eine Gewichtung der einzelnen Fragen vornehmen, indem sie den Punktewert einer Frage selbst bestimmen können. Ferner kann zwischen verschiedenen Fragetypen, wie unter anderem Single-Choice, Multiple-Choice oder Freitext-Fragen, gewählt werden und jede Frage einer zuvor erstellten Kategorie zugeordnet werden. Fragen und Quizzes können also erstellt und konfiguriert werden. Allerdings wird auch keine Alternative dargelegt, als Inhalte mit dem eigenen Authoring Tool einzupflegen. Es fehlt die Funktion zum importieren und exportieren von Inhalten, was die Flexibilität einschränkt. Zudem wird nicht beschrieben ob oder wie Inhalte persistiert werden können. Es wird davon ausgegangen, dass zumindest ein erstelltes Quiz als Ganzes abgespeichert werden kann, um es später zu verwenden. Insgesamt wird aufgrund der Abwesenheit wichtiger Informationen zum Authoring Tool angenommen, dass der Entwicklungsfokus nicht auf dem Authoring Tool lag und deshalb nur unbedingt notwendige Funktionen eingebaut wurden. Sollte die Anwendung weiterhin in Lehrveranstaltungen eingesetzt werden wäre es wünschenswert den Autoren der Quizzes mehr Funktionen, die die Wiederverwendbarkeit und Zeitersparnis erhöhen, an anzubieten. Außerdem wäre es 

\begin{figure}[htbp]
\centerline{\includegraphics[width=3.5in]{./img/lom.png}}
\caption{Learning Object Model des ViSH Editors \cite[S. 3]{Gordillo2015}}
\label{lom}
\end{figure}

\subsection{Integration in den Unterrichtsablauf}
A und B verfolgen unterschiedliche allgemeine Grundkonzepte. A lässt sich vollständig in die eigentlich Präsentation Vortragender integrieren. B dagegen stellt eher ein alleinstehendes, abgeschlossenes Quiz dar und wird nicht in den Vortrag selbst integriert. Der Unterrichtsablauf wird sowohl beim Einsatz von A als auch B für kurze Zeit unterbrochen, bis die Quiz-Anwendung gestartet wurde und alle Lernenden sich mit Hilfe eines QR-Codes, bzw. einer URL für das Quiz angemeldet haben. Bei B muss das Quiz vollständig zuende gespielt oder vorzeitig beendet werden, um mit der Präsentation fortzufahren. Bei A dagegen ist das Quiz mit in die Präsentation integriert und kann mit den Inhalten darin direkt verknüpft werden. Es besteht somit auch die Möglichkeit nur vereinzelte Fragen auf einzelnen Folien einzubinden, um gezielt wichtige Verständnisfragen zu klären, bevor die Präsentation fortgesetzt wird. Letztlich stellt ein Quiz bei B ein abgeschlossenes Spiel mit Endpunktzahl da. Wogegen es bei A weniger, um den Charakter eines tatsächlichen Spiels geht. A ermöglicht es dafür eine fast nahtlose verschmelzung mit der eigentlichen Präsentation zu erreichen, was eine sehr gute Integration in den Unterrichtsablauf erlaubt.

\subsection{Vorgehensweise bei der Evaluation}
Die Evaluation fällt bei A wesentlich detaillierter und zielgerichteter aus als bei B. Die Befragung von 30 Studenten bei B lässt durch die geringe Anzahl von Ergebnissen lediglich eine Tendenz für die Nützlichkeit und Akzeptanz der Anwendung erkennen. Da der Vergleich zu anderen ARS oder Elementen der Lehrveranstaltung dabei nicht berücksichtigt wird, könnte die Evaluation von B zum Teil auch als allgemeines Meinungsbild zu Hörsaalspielen gesehen werden. Wie allerdings in der Einleitung von B bereits angedeutet, dass mit Hörsaalspielen eine höhere Beteiligung von Studierenden an der Lehrveranstaltung feststellbar ist und die Interaktion mit den Lerninhalten gesteigert wird. Darüber hinaus wurde der motivierende und aktivierende Charakter von Gamification bereits positiv nachgewiesen \cite[S. 339f]{Hobert2017}. Zwar bezieht sich der Fragebogen speziell auf die StudiDuell App, aber Ergebnisse, wie dass der Einsatz der StudiDuell-App sinnvoll sei oder Spaß bereite sind aufgrund fehlender Vergleiche und Erfahrungen mit anderen Hörsaalspielen nicht eindeutig auf die App selbst übertragbar. Es könnte angenommen werden, die StudiDuell App schneidet in den im Fragebogen abgefragten Punkten lediglich besser ab als die eigentliche Präsentation zur Lehrveranstaltung.

Die Gesamtevaluation bei A besteht dagegen aus drei unabhängigen Evaluationen. Eine ermittelt die Nützlichkeit und Bedienbarkeit des ARS aus Sicht der Lernenden und Lehrenden. Allerdings ist auch in diesem Fall die Aussagekraft nur begrenzt, da zu wenige Personen befragt wurden, um mehr als eine Tendenz ausmachen zu können. Darüber hinaus sind die Fragebögen mit drei Fragen an die Studenten und fünf Fragen an die beiden Dozenten zu undifferenziert als das repräsentative Erkenntnisse daraus gewonnen werden könnten. Lediglich grobe Mängel der Anwendung hätten mit dieser Methode womöglich identifiziert werden können. Trotzdem ist zumindest der Ansatz nicht nur die Studenten sondern auch die Dozenten zu befragen sinnvoll.
Durch weitere Evaluation untersuchten Gordillo et. al die Benutzbarkeit und den Gesamteindruck des Authoring Tool, dem ViSH Editor. 67 von allen Autoren die innerhalb der letzten drei Monate vor der Befragung LOs veröffentlicht hatten füllten dafür einen Fragebogen mit 13 Fragen aus. Die Vorgehensweise alle aktuell Aktiven Nutzer potenziell in die Befragung mit einzubeziehen, führte zu einer guten Durchmischung von verschiedenen Nutzungskontexten, wie Schullehrern, Dozenten und Forschern. Außerdem stellte sich ein ausgewogenes Geschlechterverhältnis ein sowie die Teilnahme sehr unterschiedlicher Altersgruppen. Die Fragen selbst zielen außerdem gezielt auf einzelne Funktionen des ViSH Editors ab, wodurch nicht nur die Entwickler des Tools, sondern auch Entwickler anderer Authoring Tools die Erkenntnisse bei der Planung von unterstützten Funktionen mit in die Konzeption und Entwicklung einbeziehen können. Damit ist die Evaluation des Authoring Tools wesentlich aussagekräftiger als die des ARS.
Zuletzt wurde zusätzlich untersucht, wie LOs in denen Quizzes vorkommen im Vergleich zu LOs ohne Quizzes von ausgewählten Testpersonen bewertet werden. Dafür haben 15 mit der ViSH Plattform erfahrene Testpersonen insgesamt 209 verschiedene ViSH Präsentationen Evaluiert. Dafür wurden von den Testpersonen gewichtete LORI Kriterien verwendet, die speziell dazu entwickelt wurden LOs zu evaluieren. Nach der Evaluation wurden die LOs danach gruppiert ob mindestens ein Quiz darin vorkommt oder nicht. Das Ergebnis zeigt, dass LOs mit Quizzes deutlich besser bewertet wurden, was durch Cohen's d Effektgröße ermittelt wurde. Die Ergebnisse sind durch die Menge an evaluierten Präsentationen zwar aussagekräftig, doch fehlen einige Informationen zu den Rahmenbedingungen unter denen die Evaluation durchgeführt wurde. So ist unter anderem nicht bekannt ob die Testpersonen vorher wussten, dass der Einfluss von Quizzes in LOs untersucht wird oder wie die Verteilung der LOs bezogen auf einzelne Autoren war. Dennoch stellt die Vorgehensweise eine Evaluation nach standardisierten Kriterien, mit professioneller Bestimmung des tatsächlichen Unterschieds und anschließender kritischer Hinterfragung beim Ergründen der Ergebnisse eine gute Vorgehensweise und Aussagekraft dar.

\section{Fazit und Ausblick}
Auf Basis der Analyse und anschließender Bewertung beider Vergleichsgegenstände anhand der zuvor bestimmten Kriterien, ist zu beobachten, dass die StudiDuell App in allen untersuchten Punkten schlechter bewertet wurde als das LVWBL. Der ViSH Editor bietet mehr zeitsparende und nützliche Funktionen und durch die Integration der Quizzes in die eigentliche Präsentation werden diese zudem besser in den Unterricht integriert. Ferner wurde festgestellt, dass die Evaluation beider Systeme zum Teil Mängel aufweist, wobei das LVWBL allerdings differenzierter und unter Einbeziehung des Authoring Tools und der Lehrkräfte evaluiert wurde. 

Trotzdem kann festgestellt werden, dass das StudiDuell Konzept sich deutlich vom LVWBL unterscheidet. Der Gaming-Faktor wurde mehr in den Vordergrund gestellt und insgesamt StudiDuell eher als alleinstehendes Spiel anzusehen, welches unter anderem im Unterrichtskontext verwendet werden kann. Das LVWBL ist weniger als Spiel anzusehen, sondern als eine sinnvolle Ergänzung zum vorhandenen ViSH Projekt. Der ViSH Editor und weitere Komponenten existierten bereits vor der Einbindung der Quizzes und des ARS, weshalb der Vergleich im Nachhinein unter verschiedenen Ausgangsvoraussetzungen stattfand. Dennoch kann ebenfalls festgestellt werden, dass das Paper zum StudiDuell kaum neue wissenschaftliche Erkenntnisse liefert, sondern lediglich bereits vorherige Studien zu Gamification Ansätzen in der Lehre bestätigt.

Die StudiDuell App erscheint sinnvoll für den gelegentlichen Einsatz als spielerisches Element innerhalb einzelner Lehrveranstaltungen, doch weniger für den hochfrequentierten und regelmäßigen Gebrauch, da das Authoring Tool zu wenige zeitsparende Funktionen bereitstellt. Dafür ist der Ansatz der StudiDuell App auch als alleinstehendes Spiel mit zuvor eingepflegten Fragen zu einem bestimmten Thema denkbar. Zum Beispiel könnte eine Art Spiele App wie \emph{StudiDuell Informatik} eine große Menge von Fragen und Unterthemen zu diesem Feld bereitstellen, von denen dann eine zufällige Untermenge in einer Spielrunde ausgewählt wird. Ein Einsatz des Ansatzes könnte also nicht nur Als Ergänzung im Unterricht, sondern auch neben dem Unterricht sinnvoll sein.

Der Einsatz des LVWBL erscheint vor allem dann sinnvoll, wenn in der gesamten Lehrveranstaltung mit dem ViSH Ökosystem  gearbeitet wird, also möglichst viele zu vermittelnde Inhalte in das System eingepflegt werden, um die Stärken bei der Wiederverwendbarkeit voll ausschöpfen zu können. Neben der Quiz Erweiterung sind als Ergänzung weitere Module denkbar, die die Interaktion mit und unter den Lernenden verbessern oder weitere Gamification Elemente hinzufügen.

Um diese und weitere ARS und Authoring Tools sowie damit zusammenhängende Systeme besser zu untersuchen, könnten weitere Kriterien ermittelt werden, die für den Einsatz der Systeme Relevanz haben. Außerdem könnten durch eine Nutzerevaluation mehrerer Systeme in relation zueinander defizite und vorteile verschiedener Systeme besser identifiziert werden.

%========== TEMPLATE INSTRUCTIONS & EXAMPLES ==========%
\renewcommand{\refname}{Referenzen}
\bibliographystyle{deIEEEtran}
\bibliography{bibfile}



%\section{Ease of Use}
%
%\subsection{Units}
%\begin{itemize}
%\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
%\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
%\item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
%\item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
%\end{itemize}
%
%\subsection{Equations}
%Number equations consecutively. To make your 
%equations more compact, you may use the solidus (~/~), the exp function, or 
%appropriate exponents. Italicize Roman symbols for quantities and variables, 
%but not Greek symbols. Use a long dash rather than a hyphen for a minus 
%sign. Punctuate equations with commas or periods when they are part of a 
%sentence, as in:
%\begin{equation}
%a+b=\gamma\label{eq}
%\end{equation}
%
%Be sure that the 
%symbols in your equation have been defined before or immediately following 
%the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
%the beginning of a sentence: ``Equation \eqref{eq} is . . .''
%
%\subsection{\LaTeX-Specific Advice}
%
%Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
%of ``hard'' references (e.g., \verb|(1)|). That will make it possible
%to combine sections, add equations, or change the order of figures or
%citations without having to go through the file line by line.
%
%Please don't use the \verb|{eqnarray}| equation environment. Use
%\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
%environment leaves unsightly spaces around relation symbols.
%
%Please note that the \verb|{subequations}| environment in {\LaTeX}
%will increment the main equation counter even when there are no
%equation numbers displayed. If you forget that, you might write an
%article in which the equation numbers skip from (17) to (20), causing
%the copy editors to wonder if you've discovered a new method of
%counting.
%
%{\BibTeX} does not work by magic. It doesn't get the bibliographic
%data from thin air but from .bib files. If you use {\BibTeX} to produce a
%bibliography you must send the .bib files. 
%
%{\LaTeX} can't read your mind. If you assign the same label to a
%subsubsection and a table, you might find that Table I has been cross
%referenced as Table IV-B3. 
%
%{\LaTeX} does not have precognitive abilities. If you put a
%\verb|\label| command before the command that updates the counter it's
%supposed to be using, the label will pick up the last counter to be
%cross referenced instead. In particular, a \verb|\label| command
%should not go before the caption of a figure or a table.
%
%Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
%will not stop equation numbers inside \verb|{array}| (there won't be
%any anyway) and it might stop a wanted equation number in the
%surrounding equation.
%
%\subsection{Some Common Mistakes}\label{SCM}
%\begin{itemize}
%\item The word ``data'' is plural, not singular.
%\item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
%\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
%\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
%\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
%\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
%\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
%\item Do not confuse ``imply'' and ``infer''.
%\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
%\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
%\item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
%\end{itemize}
%An excellent style manual for science writers is \cite{b7}.
%
%\subsection{Authors and Affiliations}
%\textbf{The class file is designed for, but not limited to, six authors.} A 
%minimum of one author is required for all conference articles. Author names 
%should be listed starting from left to right and then moving down to the 
%next line. This is the author sequence that will be used in future citations 
%and by indexing services. Names should not be listed in columns nor group by 
%affiliation. Please keep your affiliations as succinct as possible (for 
%example, do not differentiate among departments of the same organization).
%
%\subsection{Identify the Headings}
%Headings, or heads, are organizational devices that guide the reader through 
%your paper. There are two types: component heads and text heads.
%
%Component heads identify the different components of your paper and are not 
%topically subordinate to each other. Examples include Acknowledgments and 
%References and, for these, the correct style to use is ``Heading 5''. Use 
%``figure caption'' for your Figure captions, and ``table head'' for your 
%table title. Run-in heads, such as ``Abstract'', will require you to apply a 
%style (in this case, italic) in addition to the style provided by the drop 
%down menu to differentiate the head from the text.
%
%Text heads organize the topics on a relational, hierarchical basis. For 
%example, the paper title is the primary text head because all subsequent 
%material relates and elaborates on this one topic. If there are two or more 
%sub-topics, the next level head (uppercase Roman numerals) should be used 
%and, conversely, if there are not at least two sub-topics, then no subheads 
%should be introduced.
%
%\subsection{Figures and Tables}
%\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
%bottom of columns. Avoid placing them in the middle of columns. Large 
%figures and tables may span across both columns. Figure captions should be 
%below the figures; table heads should appear above the tables. Insert 
%figures and tables after they are cited in the text. Use the abbreviation 
%``Fig.~\ref{fig}'', even at the beginning of a sentence.
%
%\begin{table}[htbp]
%\caption{Table Type Styles}
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%\cline{2-4} 
%\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%\hline
%copy& More table copy$^{\mathrm{a}}$& &  \\
%\hline
%\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%\end{tabular}
%\label{tab1}
%\end{center}
%\end{table}
%%\begin{figure}[htbp]
%%\centerline{\includegraphics{fig1.png}}
%%\caption{Example of a figure caption.}
%%\label{fig}
%%\end{figure}
%Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
%rather than symbols or abbreviations when writing Figure axis labels to 
%avoid confusing the reader. As an example, write the quantity 
%``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
%units in the label, present them within parentheses. Do not label axes only 
%with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
%\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
%quantities and units. For example, write ``Temperature (K)'', not 
%``Temperature/K''.
%
%\section*{Acknowledgment}
%
%The preferred spelling of the word ``acknowledgment'' in America is without 
%an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
%G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
%acknowledgments in the unnumbered footnote on the first page.
%
%\section*{References}
%
%Please number citations consecutively within brackets \cite{b1}. The 
%sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
%number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
%the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''
%
%Number footnotes separately in superscripts. Place the actual footnote at 
%the bottom of the column in which it was cited. Do not put footnotes in the 
%abstract or reference list. Use letters for table footnotes.
%
%Unless there are six authors or more give all authors' names; do not use 
%``et al.''. Papers that have not been published, even if they have been 
%submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
%that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
%Capitalize only the first word in a paper title, except for proper nouns and 
%element symbols.
%
%For papers published in translation journals, please give the English 
%citation first, followed by the original foreign-language citation \cite{b6}.



%\begin{thebibliography}{00}
%\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
%\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
%\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
%\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
%\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
%\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
%\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
%\end{thebibliography}
%\vspace{12pt}

\end{document}
